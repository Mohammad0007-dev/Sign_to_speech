# Sign to Speech Conversion using Machine Learning

This project implements a machine learning system that converts sign language gestures into audible speech. It leverages computer vision and deep learning techniques to recognize sign language from images or video frames and translates it into spoken words.

## üöÄ Features

- Sign language recognition using a trained ML model
- Speech synthesis of recognized signs
- Real-time or batch processing support
- Easy-to-use interface (CLI or GUI, depending on implementation)

## üìÅ Project Structure


## üß† Model

> The model is trained on a dataset of sign language images each recognized sign to a corresponding word, which is then converted to speech using a text-to-speech (TTS) engine like  `pyttsx3`.

## üóÇÔ∏è Dataset

> The dataset used for training is not included in this repository due to size constraints. You can create your own dataset for practice using `datacollection.py/` or use pretrained model`Final Model/` folder.


##
Model was trained using Teachable Machine by google.

## ‚öôÔ∏è Installation

1. Clone the repo:
```bash
git clone https://github.com/Mohammad0007-dev/Sign_to_speech.git
